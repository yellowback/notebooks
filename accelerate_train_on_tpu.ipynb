{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "accelerate-train-on-tpu.ipynb",
      "provenance": [],
      "mount_file_id": "1VahBRCT4GN4iPc2vp12Q53DED1OB-zo_",
      "authorship_tag": "ABX9TyNCct9AjDhOFEfbwVCLoWc1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yellowback/notebooks/blob/main/accelerate_train_on_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P6b3uqfzpDI"
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXs1MNqGBgnq",
        "outputId": "af027e1d-b30a-446d-9b7d-d6b4b22e0ee8"
      },
      "source": [
        "!pip install transformers accelerate datasets==1.11.0 fugashi ipadic"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.4.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting datasets==1.11.0\n",
            "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 63.4 MB/s \n",
            "\u001b[?25hCollecting fugashi\n",
            "  Downloading fugashi-1.1.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (490 kB)\n",
            "\u001b[K     |████████████████████████████████| 490 kB 57.8 MB/s \n",
            "\u001b[?25hCollecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (4.6.4)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (4.62.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (0.70.12.2)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (0.3.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting fsspec>=2021.05.0\n",
            "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.11.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (3.0.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 60.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.9.0+cu102)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.11.0) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.11.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.11.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.11.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Building wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=d723107c8cd13257302ea51bab3bc6bfc6083e855ddcc929a933fdf2b10e43c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n",
            "Successfully built ipadic\n",
            "Installing collected packages: xxhash, tokenizers, sacremoses, pyyaml, huggingface-hub, fsspec, transformers, ipadic, fugashi, datasets, accelerate\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed accelerate-0.4.0 datasets-1.11.0 fsspec-2021.8.1 fugashi-1.1.1 huggingface-hub-0.0.17 ipadic-1.0.0 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2 xxhash-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUB12htcqU9W",
        "outputId": "749229f5-7f0a-4613-fc4f-60f06583296c"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-xla==1.9\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 149.9 MB 32 kB/s \n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.34.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Installing collected packages: google-api-python-client, torch-xla, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.278 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnuJzg4UCOhy",
        "outputId": "51ba5c6a-eb6d-4b47-d467-9aa08da18c71"
      },
      "source": [
        "!git clone -b v4.10.0 https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 84195, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 84195 (delta 28), reused 50 (delta 15), pack-reused 84115\u001b[K\n",
            "Receiving objects: 100% (84195/84195), 67.28 MiB | 19.81 MiB/s, done.\n",
            "Resolving deltas: 100% (60426/60426), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su_UOljHlzwv"
      },
      "source": [
        "!ln -s /content/drive/MyDrive/colab/ldn ."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PcF8DGPxWDI",
        "outputId": "f83d7574-f91c-475d-c898-dece08eb8869"
      },
      "source": [
        "!accelerate config"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.9...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.9...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.9\n",
            "In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0\n",
            "Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU): 3\n",
            "What is the name of the function in your script that should be launched in all parallel scripts? [main]: \n",
            "How many processes in total will you use? [1]: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aczvQWo5k5EF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f915202-3bbc-419c-d373-1dfa2d81ef35"
      },
      "source": [
        "MODEL=\"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
        "OUTDIR=\"./output\"\n",
        "BS=8\n",
        "SEQLEN=512\n",
        "EPOCH=5\n",
        "!accelerate launch ./transformers/examples/pytorch/text-classification/run_glue_no_trainer.py \\\n",
        "       --model_name_or_path {MODEL} \\\n",
        "       --output_dir {OUTDIR} \\\n",
        "       --per_device_train_batch_size {BS} \\\n",
        "       --per_device_eval_batch_size {BS} \\\n",
        "       --max_length {SEQLEN} \\\n",
        "       --train_file ldn/data/train.csv \\\n",
        "       --validation_file ldn/data/dev.csv \\\n",
        "       --num_train_epochs {EPOCH}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.9\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.9\n",
            "09/15/2021 10:03:15 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: xla:1\n",
            "Use FP16 precision: False\n",
            "\n",
            "09/15/2021 10:03:15 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 3\n",
            "Local process index: 3\n",
            "Device: xla:0\n",
            "Use FP16 precision: False\n",
            "\n",
            "09/15/2021 10:03:16 - WARNING - datasets.builder - Using custom data configuration default-b8cb270bea1140cf\n",
            "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-b8cb270bea1140cf/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-b8cb270bea1140cf/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
            "09/15/2021 10:03:18 - INFO - filelock - Lock 140280718824272 acquired on /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258.lock\n",
            "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpko9p9e00\n",
            "Downloading: 100% 479/479 [00:00<00:00, 384kB/s]\n",
            "storing https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
            "creating metadata file for /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
            "09/15/2021 10:03:18 - INFO - filelock - Lock 140280718824272 released on /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258.lock\n",
            "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
            "  \"transformers_version\": \"4.10.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "09/15/2021 10:03:18 - INFO - filelock - Lock 140716237044240 acquired on /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258.lock\n",
            "09/15/2021 10:03:18 - INFO - filelock - Lock 140716237044240 released on /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258.lock\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140280585906768 acquired on /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc.lock\n",
            "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpy0_x2a5n\n",
            "Downloading: 100% 110/110 [00:00<00:00, 91.0kB/s]\n",
            "storing https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc\n",
            "creating metadata file for /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140280585906768 released on /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc.lock\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140716133690000 acquired on /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc.lock\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140716133690000 released on /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc.lock\n",
            "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
            "  \"transformers_version\": \"4.10.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140280549329424 acquired on /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4.lock\n",
            "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpoa68_pd9\n",
            "Downloading: 100% 258k/258k [00:00<00:00, 2.21MB/s]\n",
            "storing https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140280549329424 released on /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4.lock\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140716237003088 acquired on /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4.lock\n",
            "09/15/2021 10:03:19 - INFO - filelock - Lock 140716237003088 released on /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4.lock\n",
            "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4\n",
            "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc\n",
            "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer.json from cache at None\n",
            "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
            "  \"transformers_version\": \"4.10.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "09/15/2021 10:03:20 - INFO - filelock - Lock 140280427884112 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpcqy0mcmz\n",
            "Downloading:  13% 56.0M/445M [00:01<00:09, 40.2MB/s]09/15/2021 10:03:22 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 2\n",
            "Local process index: 2\n",
            "Device: xla:0\n",
            "Use FP16 precision: False\n",
            "\n",
            "Downloading:  18% 81.0M/445M [00:01<00:09, 38.8MB/s]09/15/2021 10:03:22 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 4\n",
            "Local process index: 4\n",
            "Device: xla:0\n",
            "Use FP16 precision: False\n",
            "\n",
            "Downloading:  32% 143M/445M [00:03<00:07, 42.9MB/s]09/15/2021 10:03:24 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 5\n",
            "Local process index: 5\n",
            "Device: xla:0\n",
            "Use FP16 precision: False\n",
            "\n",
            "Downloading:  34% 151M/445M [00:03<00:08, 35.8MB/s]09/15/2021 10:03:24 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 7\n",
            "Local process index: 7\n",
            "Device: xla:0\n",
            "Use FP16 precision: False\n",
            "\n",
            "Downloading:  44% 195M/445M [00:05<00:06, 37.6MB/s]09/15/2021 10:03:25 - INFO - run_glue_no_trainer - Distributed environment: TPU\n",
            "Num processes: 8\n",
            "Process index: 6\n",
            "Local process index: 6\n",
            "Device: xla:0\n",
            "Use FP16 precision: False\n",
            "\n",
            "Downloading: 100% 445M/445M [00:11<00:00, 39.2MB/s]\n",
            "storing https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb\n",
            "creating metadata file for /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140280427884112 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "loading weights file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140706795278288 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140706795278288 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 139950024359696 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 139950024359696 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140716096204560 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140716096204560 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140430868516752 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140430868516752 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140210752769936 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140210752769936 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140429070736976 acquired on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "09/15/2021 10:03:32 - INFO - filelock - Lock 140429070736976 released on /root/.cache/huggingface/transformers/cabd9bbd81093f4c494a02e34eb57e405b7564db216404108c8e8caf10ede4fa.464b54997e35e3cc3223ba6d7f0abdaeb7be5b7648f275f57d839ee0f95611fb.lock\n",
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on dataset: 100% 6/6 [03:17<00:00, 32.94s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:18<00:00, 33.05s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:18<00:00, 33.06s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:19<00:00, 33.22s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:19<00:00, 33.22s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:18<00:00, 33.13s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:18<00:00, 33.13s/ba]\n",
            "Running tokenizer on dataset: 100% 6/6 [03:21<00:00, 33.56s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:49<00:00, 24.59s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:49<00:00, 24.74s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:49<00:00, 24.79s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:49<00:00, 24.71s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:49<00:00, 24.84s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:49<00:00, 24.75s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:48<00:00, 24.20s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:46<00:00, 23.18s/ba]\n",
            "09/15/2021 10:08:00 - INFO - run_glue_no_trainer - Sample 5711 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [2, 213, 32, 6, 7757, 25080, 1395, 12, 682, 51, 5, 13372, 52, 28495, 1118, 587, 6, 8703, 27263, 28787, 13, 1099, 2661, 3358, 5, 9084, 12, 22516, 11728, 14, 1034, 15, 10, 8, 240, 605, 77, 29112, 5, 7452, 5852, 7523, 23, 3960, 24, 29095, 3326, 16224, 8177, 643, 14, 8703, 27263, 28787, 7, 5135, 29177, 13230, 20, 10, 1099, 2661, 3358, 7, 3514, 29528, 28475, 62, 14124, 12, 12172, 40, 12212, 8, 366, 6, 2786, 12214, 45, 14, 203, 255, 6, 716, 29693, 12, 10869, 20, 10, 5, 75, 8, 12742, 40, 410, 31018, 28457, 6122, 12, 12172, 251, 118, 13, 12212, 15, 10, 7452, 643, 9, 12451, 28479, 13, 28, 16084, 255, 8, 8390, 10, 1738, 2786, 28556, 718, 80, 82, 6, 27733, 9, 2291, 3919, 29217, 6, 8703, 27263, 28787, 13, 1099, 2661, 3358, 28, 11386, 1778, 7, 20741, 28512, 19736, 75, 8, 70, 22516, 11728, 7, 9, 6, 1920, 13129, 49, 22675, 12, 28, 36, 42, 30340, 29219, 29, 7045, 28496, 4109, 5595, 11, 606, 7134, 14, 1237, 212, 10, 38, 36, 333, 1992, 75, 38, 36, 918, 18015, 16, 10, 1466, 5, 2679, 14, 798, 181, 28468, 16, 16, 23793, 38, 64, 6, 7452, 643, 11, 11386, 34, 1295, 14, 1542, 26026, 16, 33, 8, 19891, 14581, 7, 1517, 13, 11055, 2030, 7, 13440, 26, 20, 6, 3251, 9, 31, 14, 15872, 11, 3952, 16, 6, 76, 32, 219, 9, 25246, 26, 796, 8, 9680, 1634, 2622, 9594, 35, 802, 28880, 30218, 30944, 4444, 281, 11798, 160, 30404, 5, 1088, 150, 28599, 18, 20270, 35, 1099, 29525, 2782, 5, 1456, 35, 1172, 28675, 5981, 109, 13, 968, 35, 9687, 1544, 28601, 14, 1782, 35, 1685, 24589, 13, 5, 2203, 21171, 28596, 12944, 5, 2782, 9911, 1964, 362, 2686, 10, 679, 9680, 1634, 933, 9594, 35, 11449, 2480, 28538, 13670, 472, 19949, 18210, 28825, 28663, 14215, 57, 23463, 28538, 21695, 27908, 28663, 18572, 28695, 28538, 23461, 25033, 5075, 908, 23, 11239, 24, 3], 'labels': 8, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "09/15/2021 10:08:00 - INFO - run_glue_no_trainer - Sample 4143 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [2, 36, 19241, 5, 3932, 6, 10898, 80, 54, 1852, 38, 36, 1325, 28, 1778, 4479, 16, 10, 3286, 28448, 147, 1387, 14, 2857, 16, 17696, 29071, 5217, 6, 7545, 5, 28178, 23203, 40, 4799, 18989, 5, 7720, 14, 15440, 16, 2501, 70, 1419, 8, 3581, 284, 18591, 11, 9749, 695, 7, 3415, 16, 1497, 53, 28, 707, 5, 12, 9, 2935, 9394, 335, 4128, 5, 284, 12, 9, 59, 18591, 9, 8221, 8, 5233, 6, 1325, 5, 3325, 5, 2416, 760, 1568, 40, 1755, 5008, 7, 34, 5, 9, 36, 10972, 5, 17932, 11, 614, 28468, 23049, 13, 3062, 897, 10, 2416, 699, 28503, 335, 5, 20029, 30278, 28454, 26, 38, 2992, 8, 22237, 10972, 15272, 11, 4841, 2203, 2416, 699, 28503, 335, 5, 9003, 1964, 13, 28, 5327, 7755, 53, 5, 4510, 40, 1704, 29189, 8, 36, 3209, 7163, 5, 11121, 616, 7, 5846, 15, 10, 16996, 26, 7093, 1235, 5, 1473, 11, 2626, 12, 212, 16, 1, 8, 172, 1312, 5, 3568, 2470, 1514, 2721, 29733, 20806, 6, 6878, 7773, 14, 2367, 10, 22756, 7, 708, 28485, 28733, 28485, 5, 3851, 8, 3374, 573, 140, 4354, 6, 7993, 11121, 616, 140, 173, 12, 7755, 5419, 9, 1565, 29361, 8896, 38, 23, 2538, 573, 35, 335, 35, 18999, 24, 3215, 3374, 573, 12, 3568, 2470, 6172, 25675, 2992, 54, 1852, 8, 5233, 6924, 22981, 14, 744, 13518, 28504, 58, 16, 322, 10, 16996, 26, 7093, 1235, 2992, 14, 6, 10069, 5, 17594, 9, 14013, 10972, 5, 13391, 11, 798, 28700, 28468, 16, 33, 802, 4367, 8, 14, 6, 69, 3581, 5, 15736, 7, 28, 2941, 28491, 28565, 2407, 10, 53, 558, 14, 33, 124, 2992, 8, 36, 12455, 13, 12243, 3120, 12, 14716, 12, 10, 900, 5, 45, 8, 25130, 7, 18987, 10, 7038, 30598, 5, 2416, 699, 28503, 335, 25, 9840, 14, 14993, 187, 10, 8, 63, 1325, 14, 5471, 12, 5457, 16, 10, 807, 9, 26, 31050, 1143, 65, 140, 4256, 18727, 40, 3417, 6, 63, 7052, 28, 167, 30013, 28, 2563, 3807, 23603, 6, 594, 7, 20762, 16, 8697, 5, 14, 8286, 308, 10, 54, 1852, 65, 63, 744, 5, 91, 5, 4772, 462, 9, 18917, 8946, 3158, 13, 805, 51, 7, 8419, 28504, 42, 29231, 12, 2203, 6179, 9, 22752, 10, 1964, 5298, 11, 19545, 8, 604, 7038, 30598, 15, 16, 1325, 558, 7, 28, 668, 14769, 28555, 23269, 12, 322, 10, 947, 12355, 7, 8272, 16, 3318, 6, 63, 9039, 28447, 558, 10135, 28781, 14, 18, 1281, 8, 10756, 5068, 14, 12708, 80, 630, 24442, 3158, 13, 16357, 26, 62, 23704, 8, 243, 28779, 3828, 16, 4605, 28547, 3913, 10, 38, 23, 1959, 573, 35, 335, 35, 18999, 24, 276, 19, 174, 7, 36, 2521, 29064, 384, 2633, 38, 36, 5095, 28652, 335, 38, 15060, 1866, 14, 4459, 7, 297, 3913, 10, 14, 6, 10972, 15272, 7, 845, 129, 12, 20315, 28478, 28719, 5709, 5270, 18, 315, 11, 5457, 10, 2416, 699, 28503, 969, 40, 2867, 13, 6, 744, 5, 41, 35, 525, 201, 5, 23622, 9, 8276, 3426, 203, 80, 5, 11655, 205, 3], 'labels': 0, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "09/15/2021 10:08:00 - INFO - run_glue_no_trainer - Sample 707 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [2, 36, 18060, 76, 49, 12018, 1975, 24993, 28535, 9, 1473, 11, 7237, 29, 2935, 10290, 5, 7468, 28672, 28598, 11, 2359, 12, 3226, 38, 11, 212, 10, 53, 7, 9, 6, 6739, 28475, 28469, 3226, 34, 727, 28, 80, 14, 10271, 28486, 343, 20, 10, 7468, 28672, 28598, 5, 12872, 7415, 12, 9, 6, 3252, 15, 16, 21, 10, 18060, 76, 49, 127, 5499, 12018, 1975, 24993, 28535, 1162, 602, 9, 316, 10, 8, 1142, 6, 1842, 8653, 28687, 8505, 12395, 13, 8653, 28687, 8505, 4768, 5, 656, 14, 10912, 26, 20, 10, 8, 1208, 5, 21485, 14, 8653, 28687, 8505, 4768, 12, 6, 359, 5499, 1317, 14, 852, 26, 20, 330, 143, 57, 5499, 5, 26195, 8814, 11545, 11, 1389, 34, 1317, 14, 2143, 26, 62, 45, 7, 58, 10, 8, 3794, 50, 9, 324, 176, 5, 3096, 30108, 11545, 1389, 9611, 140, 45, 7, 139, 8, 330, 143, 57, 5499, 5, 26195, 8814, 11545, 12175, 9, 6, 17083, 14, 965, 20112, 3764, 10229, 18828, 13, 483, 5499, 8653, 28687, 8505, 12395, 5, 9661, 28464, 3764, 7923, 18828, 1876, 5, 2604, 4401, 118, 13, 5308, 15, 16, 33, 8, 893, 8653, 28687, 8505, 12395, 465, 4768, 360, 7, 8863, 14, 363, 28985, 28825, 7104, 5931, 4209, 118, 13, 5308, 15, 12568, 28451, 7, 97, 240, 3581, 5, 22276, 22401, 3042, 731, 14, 1389, 26, 62, 8, 18199, 28, 8653, 28687, 8505, 12395, 12, 9, 134, 383, 12274, 6, 8653, 28687, 8505, 4768, 12, 9, 1208, 379, 383, 12274, 126, 11176, 519, 75, 8, 8333, 28672, 12, 9, 332, 4709, 28672, 1389, 14, 2582, 13, 297, 8653, 28687, 8505, 4768, 12, 9, 1208, 12, 4852, 28501, 236, 12274, 140, 42, 6980, 4709, 28672, 14, 1389, 519, 7, 58, 16, 33, 8, 8653, 28687, 8505, 4768, 9, 9278, 8406, 5, 22276, 8333, 15433, 4018, 11668, 10563, 7, 1334, 16, 24595, 4905, 6907, 5, 9189, 28718, 430, 2953, 6081, 15381, 236, 126, 1389, 34, 8, 7993, 26192, 8900, 1043, 12, 31, 24595, 4905, 6907, 5, 10018, 28566, 2241, 1368, 14230, 7, 28, 1277, 15, 16, 33, 4895, 12, 26192, 3255, 14, 727, 7, 8093, 312, 4356, 28524, 834, 7, 20193, 45, 14, 519, 7, 58, 16, 33, 124, 75, 8, 375, 7, 28, 6, 5890, 1433, 12120, 24741, 5791, 14884, 376, 9, 6, 482, 25, 3521, 83, 7, 41, 1909, 11, 13963, 39, 143, 5191, 1909, 12, 1530, 26, 62, 45, 7, 58, 16, 33, 8, 12120, 24741, 5791, 14884, 376, 9, 6218, 2628, 51, 962, 5589, 9398, 1162, 4102, 2035, 11, 779, 7401, 12, 1676, 5, 1078, 3174, 14, 11059, 1842, 6218, 2628, 1043, 36, 17157, 12251, 28682, 38, 1162, 1197, 14, 1389, 26, 62, 8, 106, 25576, 28890, 12068, 28, 6215, 623, 7, 139, 13, 625, 8, 375, 7, 9, 562, 14, 137, 18, 165, 1555, 28466, 75, 35, 18451, 2879, 14, 27905, 15, 1197, 2808, 7, 1334, 16, 12018, 1975, 1277, 35, 8317, 28682, 241, 4437, 14, 10994, 8317, 28682, 40, 16787, 2399, 118, 13, 846, 35, 2808, 26, 20, 10, 3042, 28598, 17298, 4132, 35, 20258, 101, 656, 3], 'labels': 1, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "Downloading: 3.21kB [00:00, 2.11MB/s]       \n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer - ***** Running training *****\n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer -   Num examples = 5893\n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer -   Num Epochs = 5\n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer -   Instantaneous batch size per device = 8\n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer -   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer -   Gradient Accumulation steps = 1\n",
            "09/15/2021 10:08:28 - INFO - run_glue_no_trainer -   Total optimization steps = 465\n",
            " 20% 93/465 [03:28<04:32,  1.37it/s]09/15/2021 10:12:17 - INFO - run_glue_no_trainer - epoch 0: {'accuracy': 0.8678385416666666}\n",
            " 40% 186/465 [06:17<03:37,  1.28it/s]09/15/2021 10:15:00 - INFO - run_glue_no_trainer - epoch 1: {'accuracy': 0.912109375}\n",
            " 60% 279/465 [07:53<02:27,  1.26it/s]09/15/2021 10:16:35 - INFO - run_glue_no_trainer - epoch 2: {'accuracy': 0.9303385416666666}\n",
            " 80% 372/465 [09:28<01:19,  1.17it/s]09/15/2021 10:18:12 - INFO - run_glue_no_trainer - epoch 3: {'accuracy': 0.939453125}\n",
            "100% 465/465 [11:06<00:00,  1.27it/s]09/15/2021 10:19:49 - INFO - run_glue_no_trainer - epoch 4: {'accuracy': 0.9440104166666666}\n",
            "Configuration saved in ./output/config.json\n",
            "Model weights saved in ./output/pytorch_model.bin\n",
            "100% 465/465 [11:29<00:00,  1.48s/it]\n"
          ]
        }
      ]
    }
  ]
}